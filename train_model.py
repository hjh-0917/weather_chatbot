import json
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import LabelEncoder
import joblib
from pathlib import Path
import random

# ğŸ”¹ ë°ì´í„° ë¡œë“œ
def load_data():
    dataset = []
    personas = ["teen_female", "teen_male", "twenties_female", "twenties_male", "thirties_female", "thirties_male"]
    styles = ["cute","gentle","luxury","practical","trendy"]

    for persona in personas:
        for style in styles:
            file_path = Path(f"data/{persona}/{style}.json")
            if not file_path.exists():
                continue
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                # ëª¨ë“  ì²´í˜•, í”¼ë¶€í†¤, ë‚ ì”¨, ì‚¬ì´ì¦ˆ ë°ì´í„°ë¥¼ flatten
                for tone in ["ì›œí†¤","ì¿¨í†¤"]:
                    for shape in ["ë§ˆë¥¸","ë³´í†µ","í†µí†µ","ì—­ì‚¼ê°í˜•"]:
                        for weather in ["ë”ì›€","ì„ ì„ ","ì¶”ì›€"]:
                            outfits = data[style][persona.split("_")[1]][persona.split("_")[0]][weather][tone][shape]
                            for outfit in outfits:
                                # ì…ë ¥: persona + style + tone + shape + weather
                                X = [persona, style, tone, shape, weather]
                                # ì¶œë ¥: ìƒì˜, í•˜ì˜, ì‹ ë°œ, ì•¡ì„¸ì„œë¦¬
                                y = [outfit["ìƒì˜"], outfit["í•˜ì˜"], outfit["ì‹ ë°œ"], outfit["ì•¡ì„¸ì„œë¦¬"]]
                                dataset.append((X, y))
    return dataset

# ğŸ”¹ Label Encoding
def encode_dataset(dataset):
    X_raw = [x for x,y in dataset]
    y_raw = [y for x,y in dataset]

    X_encoders = [LabelEncoder() for _ in range(5)]
    X_encoded = []
    for i, enc in enumerate(X_encoders):
        col = [row[i] for row in X_raw]
        X_encoded.append(enc.fit_transform(col))
    X_encoded = list(zip(*X_encoded))  # [(persona, style, tone, shape, weather), ...]

    y_encoders = [LabelEncoder() for _ in range(4)]
    y_encoded = []
    for i, enc in enumerate(y_encoders):
        col = [row[i] for row in y_raw]
        y_encoded.append(enc.fit_transform(col))
    y_encoded = list(zip(*y_encoded))  # [(ìƒì˜, í•˜ì˜, ì‹ ë°œ, ì•¡ì„¸ì„œë¦¬), ...]

    return X_encoded, y_encoded, X_encoders, y_encoders

# ğŸ”¹ ëª¨ë¸ ì •ì˜ (ë‹¤ì¤‘ ì¶œë ¥)
class OutfitNet(nn.Module):
    def __init__(self, input_size, hidden_size, output_sizes):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.output_layers = nn.ModuleList([nn.Linear(hidden_size, out_size) for out_size in output_sizes])

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        outputs = [layer(x) for layer in self.output_layers]
        return outputs

# ğŸ”¹ í•™ìŠµ
def train():
    dataset = load_data()
    X_encoded, y_encoded, X_encoders, y_encoders = encode_dataset(dataset)

    # Tensor ë³€í™˜
    X_tensor = torch.tensor(X_encoded, dtype=torch.float32)
    y_tensor = [torch.tensor([yi[i] for yi in y_encoded], dtype=torch.long) for i in range(4)]

    model = OutfitNet(input_size=5, hidden_size=128, output_sizes=[len(enc.classes_) for enc in y_encoders])
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(100):
        optimizer.zero_grad()
        outputs = model(X_tensor)
        loss = sum([criterion(outputs[i], y_tensor[i]) for i in range(4)])
        loss.backward()
        optimizer.step()
        if (epoch+1) % 20 == 0:
            print(f"Epoch {epoch+1}/100 Loss: {loss.item():.4f}")

    # ğŸ”¹ ì €ì¥
    torch.save(model.state_dict(), "outfit_model.pth")
    joblib.dump(X_encoders, "X_encoder.pkl")
    joblib.dump(y_encoders, "y_encoder.pkl")
    print("ëª¨ë¸ê³¼ ì¸ì½”ë” ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    train()
